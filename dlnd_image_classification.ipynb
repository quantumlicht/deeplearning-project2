{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHF9JREFUeJzt3UmPZOl1HuAvxsyMrKzKqsqau6rYA5vNbropkjJJmYIs\nUIBXWtn+BV7YO/8Yr73wymtDNAwIggwSMEmBNMeW2Wz2VOzumquyco6M2QttzI2Bc5gChYPn2Z88\nEd+9cd+8q7ezWq0aAFBT9w/9AQCAfzyCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/T/0B/jH8l/+w79fZebGx9PwTK+f\n+3+pc/tGeGZvtJHa9faFYWruk1/+LDzznR/+PLVrbzILz/R6ybPvdFJzg7X18MylKzupXec34t/t\n83eupHb9+be+Hp6Zz+LXq7XWnu0fpeYGWxfDM+9+8NvUrr/97g/jQ8nnwNogN3dhMAjPDPuL1K5p\n4lrPZ7nfWFstU2NrvbXwzMkq/rxvrbUXp/F46eZ+Lu073/+75EH+P7t/3z8AAPzTJegBoDBBDwCF\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+te3P84NddfxJuT\nBv1UUV67v5qEZ94f5yqQ3v7iK6m55TT+Ga/t5NraNlLfLXf22fa6k0n8PPZ3X6R2HXXiTWOT03Fq\n15e/+o3wzOzkNLXr2fPceVxbjzc3LqcHqV0ba/H7atlyrWtXt86l5r70ymvhmadP7qd2jceH4Zmj\no1xLYevGW/laa22tPw/P3Lx+IbVrNrwanvngV/dSu86CN3oAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZUpuPT9dScyfj/fDMsJMr92iLeKFCtzNMrXr2\n28epuZ88+Cw88+snudKS1SReSpEtp1lfX0/NzebxopnWzf0/vb4Rv4f3xrlilR+983545sblXCHI\nZJ67ZpkCo7XkE24wSHzG3NG3L7z6amruc3fuhme2t0apXY8e3gvPLGe55+K5izdSc4tBvPRotJYr\n3rm5Ey8i+rSXO/uz4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLLtdeNeriFrtxtvJ+ssJqldl/vx4z93/mJq1+lxvJWvtdb2DuPf7eB0ltq1\nSpz9YpFok2ut9ZKfsZ/533gWb11rrbXjafzsz61yu370i1+GZ15/7bXUrjdevZOa6w/j7V+f+1yu\nGe54OQjPPH74NLXr4HCcmmvrm+GRP/6zt1Orfv7j74VnxvN4G2VrrR3Oci1vz4/jz8ZL41zD3q3e\nYXjm9Cjb2vj780YPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAorW2qz1tlNzd0YxYsYtlu8AKO11i5d3AjPfLyKlym01trmxjI1t9aJl6SMOrnbara5Fp+Z\n58ppTie5IqJF4n/jjVGupGO4Fr+vrt++kdp186Xb4ZlnR7lCkEcHuRKXb3zj6+GZ3cePUrv+9b/5\nVnjmf/z3v07t+uEP/i41d+dLXw3PfPvtr6V2fXj/o/DMx9//cWrX/nQrNXc0jz/jvvjP42fYWmvj\n2YvwzM7OemrXWfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUFjZ9rrhZu6rvbJ1NTzz8iq368Iw0Wa0/1lq12g73gzXWmvHw5PwzHKwSO364z+K\nN0lduxq/Xq219tEHH6TmPv3kfnim28u1G67m8Xa49W7u7P/kG/Gzfxq/NVprrf3oe99Nzb333p3w\nzGKc/JCbF8Mje8e5RsSjWe5964OHz8Mzx8teatfxPP4Zn+zlzmOyfi419/m7r4Rntq/dTO16+jx+\n9t/+9lupXWfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCF\nCXoAKEzQA0BhZdvrjqa5xrALvc3wzOzZi9SuT/fiTWh/+uU3UrvG0+PU3K1lfGZ9tErt+uZ2/Ozf\nvLKT2nWyzH3GZ2vxFsCT/dz9sZjGZ/rTw9Suu598HJ7Z2Jundl26sp2am/39z8Iz2ebAH/7q3fDM\new8epHadznMtb/c/iTdZPnn+NLXr61/5Znjm7vbt1K7/9F//W2puOn4UnvnJj5+ldj1+/GF45qt/\nkXt2nwVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nsLKlNld666m5W60Xnjl/fiu16+cv4qUULyb7qV13r99Izf3bJy+HZwYHuQKdy+/Hz2Ptw4epXYvl\nLDX3uU58ZrBIDLXWuv34Pbzo5EpcJj/6aXjmQrKMZbkTLy9qrbXFPNGwdLBI7TrfOxeemRzn7vtL\n8UdOa6210Wocnjl49NvUrltffD08s7WZewZ//dVbqbkn+/EWqEdHJ6ldJye74ZmP3n8/tesseKMH\ngMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx7\n3Rtbo9Tc5vNn4ZleN9Gq1Vp7/aWXwjOHj5+mdrVVrkHtVmcVnhkNc7t6iUaozjL++VprLd5z9Q8m\n3cT/xsO11K7BKv7d+pmGt9baoBtv85tt5WrXVie51rv5JH4ei5a7F69143fItzdyrXzTzjA1t7h5\nLTyzfu9eatdJ5iMmWz3feuO11NyNk/g1uzGbp3a9/urN8MxrO/FGxLPijR4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21Gb3wUepuck8XoIx7uWKRE4u\nxEsONk7i5SOttXb67oepuUVvEZ6Zb+Zuq24vXkqxlixx6bT11Nw8UQ60WOY+42owiM+kNuXm+ldf\nSe3a2su9X5wmLtn07sXUrovzo/DM5mmuKmm+lytWOXqyH545efD91K6H//sX4Znzb72e2vX8Ua64\nazq6FJ6Zj1Or2snzF+GZg0G2Suv3540eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdc+P9lJznx6fhmfmy1z71LBzPTwzuriT2vV8fJiau95b\nC89snOb+f1wcxJv5JtNcm1/byZ3j5uuvhWdOE01orbV29OwgPLO2jLfrtdZabzIJz0ye5u6ptpZr\nlOtsx9se+51cn9/yIP4c2Hgr1+bXhvHv1Vproyfx6rXj+/dTu/Z+/UF4ZvnJ49SurUtbqbnd7XhL\n5PNHud/mwyefhWdeHt5I7ToL3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAoTNADQGGCHgAKK9te9+I03j7VWmuPTuJtRrOD49SunWtXwjOr21dTu9Yu5hqh1g7i\nzXz9B09Tu6ZHJ+GZoxZvrGqttcW5jdTc4O6d8Ey/s0jt2tyOn8fsN5+kds0SLYCn3Vxz4NafvZma\nO9l7Fh9679epXW2eeAd6mPh8rbXJMte0Obh+Mzxz/V9+M7VrbaMXntn9zYepXdsn8V2ttXbhbrxp\n85NHuYa9jV68FXEwGKZ2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLKlNrdvv5Sa6358PzyzMU6taotpvBhhrTNI7XpxfJCa+8Gnn4Vnbp4epna9\n0eIHOUmUsbTW2vh+/Dq31tr0p7+K72rx69xaa51bt8Izp69fT+06mY/CM2+/miunOe6eS82NH9wL\nzwz3c+VW8/PxApLpJ8lCoce5UqzB1SfhmZNruVKswaUL4ZmLf/HV1K69Tx+m5rZ34mU4Xz13N7Xr\nb/7Xi/DM2na8xOyseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAorGx73fWb11Jzh/efhWdGFzupXa2zFh4ZdHO7Hj57npr7z7/4P+GZL1zOtZP9\nx/XN8Mwo+a/q6vgoNbf7Try9bvdKvPmrtdY+msRbzabJprybr98Mz9y5mPte04ePU3PnEq1mneU0\ntasdxn9na92N1KqD8UlqbvHRR+GZ1YNHqV0vtuLPqs0v5BpEb778amru9FH8vroyij9zWmvtK196\nLTxz++XceZwFb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAU\nJugBoLCypTb7ixepuf5qPzwz6OeOcdqLF5DszcepXbvjXNnJfBX/bgeDXLnH/cEoPLO9mqd2Tbu5\nudVqEp7ZX+ZKSz57Ei+1Od9dT+16kbhkf3X/r1K7vnDrVmru1Uvx73Z57Xpq1/G9++GZxTh+vVpr\nbbXI3YsvXjxN7Mo9B6br8VKb2X68IKy11qa/fD81N0oUOk3WB6ldd998Kzwze/Db1K6z4I0eAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdcPV\nMjXXX87CMzvdXAPStBdvrerPpqldJ6e587h15Up45qWXb6d23T9KNPOtcm1cw2RrVWce/8lMl/HG\nu9Zau3F5JzzTzxWhtYOnj8Izq91cK9+D57mWt/3RMDxzZxL/PbfWWvdZvL2ujXOH353n3rfG8/g5\nnixyz49VohVxNO6kdj28/1lqbtSJ7zue567Z9iQ+t/P266ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzcZ4lJp7ML8QnrnaPU3tujjeC8/0\nnzxM7ZofvkjNffHNl8Mzd77w+dSu3V+8F5650emldrVBrgxnsIr/b7xxlCtx6bf4ZxyNNlK7fvPh\nvfDMznHuPeGVz11KzX02jBfUPP4g93vZONwNz3TmuXuqs8jdw6eJUqxpN3fNpsfxXbuLw9Su0eh8\nau5wGi+POp7krtnu/cfhmf6d66ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeA\nwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+v2j+NNV6219t39eEvT/HJqVfvWchqe2XjyKLVrfXaS\nmvvK174dnrl5+7XUru/86J3wzP4k1xy46Ofuj1miLW9j1UntOv0sfq17l3LNcK9c3AnPnC72U7v6\nm8PU3Nt/+vXwzG680Owf5n7yJDwzWeaa0Jb9tdTcOHFfbW4mH1Ybm+GR8TDXyre8fDE1d9ri+x49\njbcUttba/t6z8MyLX7+f2vWXqanf5Y0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtddODB6m5D54/Ds+MZ7k2ru2X4o1hXx7kWte2+vFWvtZa\ne/n27fDM+XO5BrXJIt7mNzmJz7TW2nCwSM2druL7ht3c/TGcxq/ZeDfXxtXtxx8Fy16ure3x81wD\n44t3fxWeGa3nGtQO18/FZzZGqV2Tc1upuePj4/DMaCf329ydxlsiD+e531h3Nk7NPXx0FN+1Hm/l\na621g1n8ObB5kGt7PAve6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhQl6AChM0ANAYWVLbf7V3VxZwdPdeJnFjz8+Se36m3vxkoONV3Lfa3RuLTW31YsXdcwO4wUYrbW2\n6MRLMI4nuV3rvdytv+gl/jfu5P6fXnbjc7vH8WKP1lpbncYLdIbHubOf7eWKiFYffhKeGSXfZaaj\n8+GZd+aT1K57z56k5taX8ZnhMlcYM1iP/146s05q1+lerpjpeBUvB+qfG6R2LQbx73b34nZq11nw\nRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY\n2fa612/mvtq/G90Jz9xeu5/a9T/fizeN/e29WWrXH929mZo7+vDj8Mxe8v/H3jJex7U3zTUHXhnF\nm65aa22x6oVnZsvcNXu6ip/Hs1G8fbG11k778fa6rU7uN7Z5IXf2y2n8M7bnB6lda2vxlsjPTnPN\ncM8Xq9Tc9UG8eW20mbs/tjbj57Ea59oNn01z59jvxZ8Fvd3c8+NLq2F45txh7jlwFrzRA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbaTJJlJ5fWO+GZ\nP3l9J7Xr2XG8tOQn9/dTu959/CI19/lEUcd0mLutVsv4/52Hp5Pcrkm8lKK11gbr8e+2WuZKS1pi\nbmNtPbXqcBUvIDm4cy216/Jbb6TmevGfS3vnr7+X2nU7cV+9dPFKalebTFNj6/34gezPcoUxx8/j\nz9PryYKlmzuXU3PDbvy3OdjNPU/vHsYLyW5vb6d2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoA\nKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIWVba/r9HJfrTOPt1bd2M41hv2Lly+EZw6m\n8Zax1lq7t5dr8zvpxdv8rt6+ndrVG47CM6fzXDPc6eFhaq4/W4RnhoON1K743dHa/PHT1K7zi3l4\nZnKQu6d2Z4kautba9sWL8ZlO7l1mcBr/brc2N1O7hsn3rc7mWnxmkPuM3aN4w961fvz33FpriQLR\n1lpr3Un8t3mSfA5c6MXvj1fv5HLiLHijB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQ\nmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91qlatAWi0T7WTLeONda629eSl+/E9vnEvtOp7kPuN8\nHG/L27l8JbVr/Vy8r21vmWuvm01nqbl5Ym7SyzUOdju98Mz55L/umV6t6cF+btlp7jxWj56EZ15q\nuefAoBdv89sa587jai/Xbvgi0Ui5thVvAGytteUsfmPNT/ZSuw4muVbERHldW06OU7tuvHk1PPPy\nndxz8Sx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhZUttVl2cv/DLFq8SKTNcwUpF/rxwo2v3N5J7Xp+uJuamz5+GJ6ZHeeKIoab8XKP0+R1nq1yc91l\n/FovZom2jdZaZxG/P+bJ85gOMuUv8eKX1lrrzHPnsegN40PdXKnNYh7/bqtkWc/6YpCaW82m4ZlH\n67mimdla/OyXa6lVbbCZO4+Tk/h5DFfL1K4rd66HZ9b7ifv3jHijB4DCBD0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91wYzM111sfhWeme0epXZlW\ns5vb8c/XWmv/bD/XrPXu3uPwzKMHn6R2HYwPwjNHy1z71Gk39z/uYLkKz8xXuba27ir+8zzu5Nra\nTlbxuX7yPWE5yV2z5SR+D3eS7XUtcZ1P+7nrvEw05bXW2nHmM65NUrtaN/7d1ge5+rrlIt5C11pr\nm8v4d3vt2lZq18Vh/OxPnueaA3Of8Hd5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCBD0AFCboAaAwQQ8AhZUttWndXmqs0xmEZ/obqVXttDsLzwwSZQqttXbnRq4M5+PP4gUT\n08lxatdiGd+1N88VYDzr5G79rV78vuqscteskyio2c/1xbRH03hpSbeTe0/oJQp0srJvMoMWv86P\nl/Hfc2ut7bdcGc5R4lrfSpb8bCcKuHq7h6ld1/rrqbmv3b4ennn1du7hPRrHi8wmybIepTYAwP+X\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhdVtr1vm\n/oeZjE/CM9k2rk6iSWo1zTVkndvcTM3tnI83Lu0+fZLadfgoPrffy13nHySbxi4miujOJxoRW2tt\nM9FeN+vmmvIO5vG502TrWra7rteNX+thom2wtdZGqU+Z29Xv5CoHR4lrvZzNU7umi/h5bCTvjwvn\ncp+xzQ7CI0cvcmd/cD7+m+7Mc8+cndTU7/JGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrFMtfitUrMdZINasP+MDyzGucakFruONrVzfhn\n/Ok7f5/a9fzB0/DMvJO7hZ8mO9QO5vE2v9Ei2U6W+IhryXtxNYxf526iTa611jqJVr7WWuv3441h\ni1WynWwR/53N57m2tlXyMw4zx59sr1sm7qtuP/fQWbbcM27vaC8801vlzmOtuxWe6Sz/cHHrjR4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21KY7iBdg\ntNbaINHD0EkWxnR6ieNf5IozFsdHqbkbW6PwzOVB7jMOTsfhmfPLXEHKaSf3P243MTfv50pLjpfx\nuXHyXmyJEpfePLeskywU6iYKhVarZLlVJ372uW/V2qDTy80lnh8byfv+XGJss5N8DuTGWmvxwcn4\nOLUp8zgddePP0rPijR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaCwuu11/dxX660S//uscu1kLdVel2vl63dz3VrnOvHGsD9762Zq1/5JfNfPPnmW\n2vVsMk/NnS7jbWiTZK/ZMnF/LJP/uy8S36ubrG3sJGveut1sNV9cL9Hy1k9+vI1u7lk16safBVv9\n3OFvdePPuMvJdBklb5BBi/+mh8l7arWI7zpNtHOeFW/0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsqU2bbieHIyXFXRWyTaLRPHOfD5LrVomL3WmvOHG\nKLWq/eWXb4Vnrg1yhUIfPD5IzT0+jp//i3mupON02QvPTJK34rwTv86rRPFLa611e/Hv1VprvcRc\nsj+nDRIlP/1kt9VmptyqtbaWOP+1Tu5Dnu8twjMXkwU6m73cfbU+iJ9jP3crttks/hw46cTP8Kx4\noweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACis\ns8o2rwEA/+R5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/xfkBwlHN40TWAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa61820dd68>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    a = 0\n",
    "    b = 1\n",
    "    maxi = np.amax(x)\n",
    "    mini = np.amin(x)\n",
    "    # TODO: Implement Function\n",
    "    return a + (x - mini) * (b-a) / (maxi - mini)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    # TODO: Implement Function\n",
    "    b = np.zeros((x.size, 10))\n",
    "    b[np.arange(x.size),x] = 1\n",
    "    return b\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    "If you're finding it hard to dedicate enough time for this course a week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) to build each layer, except \"Convolutional & Max Pooling\" layer.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    "If you would like to get the most of this course, try to solve all the problems without TF Layers.  Let's begin!\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    shape = np.append([None],image_shape)\n",
    "    return tf.placeholder(tf.float32, shape=shape, name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.int32, shape=(None,n_classes), name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "Note: You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.  You're free to use any TensorFlow package for all the other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    #print(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # Setup\n",
    "    size = x_tensor.get_shape().as_list()\n",
    "    weight_shape = conv_ksize + (size[3],) +  (conv_num_outputs,)\n",
    "    weight = tf.Variable(tf.truncated_normal(shape=weight_shape, stddev=0.1), name='filter')\n",
    "    # Convolution\n",
    "    \n",
    "    conv_strides = (1,) + conv_strides + (1,)\n",
    "    conv_layer = tf.nn.conv2d(input = x_tensor, filter=weight, strides=conv_strides, padding='SAME', name='conv')\n",
    "\n",
    "    # Bias\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[conv_num_outputs]))\n",
    "    pre_activation = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    # ReLU\n",
    "    activation = tf.nn.relu(pre_activation)\n",
    "    \n",
    "    # Max Pooling - Non overlapping regions\n",
    "    pool_ksize = (1,) + pool_ksize + (1,)\n",
    "    pool_strides = (1,) + pool_strides + (1,)\n",
    "    \n",
    "    pooling = tf.nn.max_pool(activation, pool_strides, pool_ksize, padding='SAME')\n",
    "    \n",
    "    return pooling \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    num_features = x_tensor.get_shape()[1:].num_elements()\n",
    "    return tf.reshape(x_tensor, [-1, num_features])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=[x_tensor.get_shape().as_list()[1], num_outputs], stddev=0.1))\n",
    "    biases = tf.Variable(tf.constant(0.1, shape=[num_outputs]))\n",
    "    layer = tf.add(tf.matmul(x_tensor, weights),biases)\n",
    "    return tf.nn.relu(layer)\n",
    "    #return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.\n",
    "\n",
    "Note: Activation, softmax, or cross entropy shouldn't be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "    weights = tf.Variable(tf.truncated_normal(shape=[x_tensor.get_shape().as_list()[1], num_outputs], stddev=0.1))\n",
    "    biases = tf.Variable(tf.constant(0.1, shape=[num_outputs]))\n",
    "    layer = tf.add(tf.matmul(x_tensor, weights),biases)\n",
    "    return layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (?, 32, 32, 3)\n",
      "conv1 (?, 16, 16, 32)\n",
      "conv2 (?, 16, 16, 32)\n",
      "flat (?, 4096)\n",
      "conn1 (?, 1024)\n",
      "out (?, 10)\n",
      "input (?, 32, 32, 3)\n",
      "conv1 (?, 16, 16, 32)\n",
      "conv2 (?, 16, 16, 32)\n",
      "flat (?, 4096)\n",
      "conn1 (?, 1024)\n",
      "out (?, 10)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    print('input', x.get_shape())\n",
    "    conv1 = conv2d_maxpool(x, 32, (2,2), (1,1), (2,2), (2,2))\n",
    "    print('conv1', conv1.get_shape())\n",
    "    #conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "    \n",
    "    conv2 = conv2d_maxpool(conv1, 64, (2,2), (1,1), (2,2), (2,2))\n",
    "    print('conv2', conv1.get_shape())\n",
    "    #conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    \n",
    "    #conv3 = conv2d_maxpool(conv1, 128, (2,2), (2,2), (2,2), (2,2))\n",
    "    #print('conv3', conv2.get_shape())\n",
    "    \n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv2)\n",
    "    print('flat', flat.get_shape())\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    # Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    # fully_conn(x_tensor, num_outputs)\n",
    "    conn = fully_conn(flat, 1024)\n",
    "    conn = tf.nn.dropout(conn, keep_prob)\n",
    "    print('conn1', conn.get_shape()) \n",
    "    \n",
    "    #conn2 = fully_conn(conn1, 1024)\n",
    "    #conn2 = tf.nn.dropout(conn2, keep_prob)\n",
    "    #print('conn2', conn2.get_shape()) \n",
    "    \n",
    "    #conn3 = fully_conn(conn1, 1024)\n",
    "    #print('conn3', conn3.get_shape()) \n",
    "        \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(conn, 10)\n",
    "    print('out', out.get_shape())\n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch,\n",
    "                keep_prob: 1.})\n",
    "    \n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.})\n",
    "    print('Training Loss: {:>.10f} training Accuracy: {:>.10f} validation acc: {:.6f}'.format(loss, acc, valid_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 40\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Training Loss: 2.0094816685 training Accuracy: 0.3250000179 validation acc: 0.358000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Training Loss: 1.7472603321 training Accuracy: 0.4500000179 validation acc: 0.426800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Training Loss: 1.5175167322 training Accuracy: 0.5500000119 validation acc: 0.464200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Training Loss: 1.3680025339 training Accuracy: 0.5250000358 validation acc: 0.483400\n",
      "Epoch  5, CIFAR-10 Batch 1:  Training Loss: 1.2176684141 training Accuracy: 0.6000000238 validation acc: 0.509400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Training Loss: 1.0904657841 training Accuracy: 0.7000000477 validation acc: 0.507400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Training Loss: 0.9838789105 training Accuracy: 0.7500000000 validation acc: 0.522200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Training Loss: 0.8696488738 training Accuracy: 0.7999999523 validation acc: 0.536400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Training Loss: 0.7816356421 training Accuracy: 0.8500000238 validation acc: 0.540800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Training Loss: 0.6558722258 training Accuracy: 0.8500000238 validation acc: 0.544200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Training Loss: 0.6026777029 training Accuracy: 0.8750000000 validation acc: 0.554800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Training Loss: 0.4887394309 training Accuracy: 0.9000000358 validation acc: 0.567600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Training Loss: 0.4110406339 training Accuracy: 0.9250000119 validation acc: 0.571600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Training Loss: 0.3396342099 training Accuracy: 0.9499999881 validation acc: 0.566800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Training Loss: 0.2793275416 training Accuracy: 0.9749999642 validation acc: 0.574200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Training Loss: 0.2464008629 training Accuracy: 0.9749999642 validation acc: 0.579400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Training Loss: 0.1919791698 training Accuracy: 0.9749999642 validation acc: 0.588200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Training Loss: 0.1587026864 training Accuracy: 1.0000000000 validation acc: 0.586000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Training Loss: 0.1149766594 training Accuracy: 1.0000000000 validation acc: 0.589400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Training Loss: 0.0908014029 training Accuracy: 1.0000000000 validation acc: 0.589000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Training Loss: 0.0723576695 training Accuracy: 1.0000000000 validation acc: 0.597400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Training Loss: 0.0618606620 training Accuracy: 1.0000000000 validation acc: 0.595800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Training Loss: 0.0410229117 training Accuracy: 1.0000000000 validation acc: 0.602200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Training Loss: 0.0390212722 training Accuracy: 1.0000000000 validation acc: 0.595200\n",
      "Epoch 25, CIFAR-10 Batch 1:  Training Loss: 0.0314790681 training Accuracy: 1.0000000000 validation acc: 0.602600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Training Loss: 0.0269406661 training Accuracy: 1.0000000000 validation acc: 0.596400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Training Loss: 0.0200205836 training Accuracy: 1.0000000000 validation acc: 0.592000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Training Loss: 0.0159730874 training Accuracy: 1.0000000000 validation acc: 0.587200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Training Loss: 0.0136358896 training Accuracy: 1.0000000000 validation acc: 0.587400\n",
      "Epoch 30, CIFAR-10 Batch 1:  Training Loss: 0.0128556592 training Accuracy: 1.0000000000 validation acc: 0.596800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Training Loss: 0.0103685018 training Accuracy: 1.0000000000 validation acc: 0.596800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Training Loss: 0.0047606668 training Accuracy: 1.0000000000 validation acc: 0.599800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Training Loss: 0.0057531931 training Accuracy: 1.0000000000 validation acc: 0.592000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Training Loss: 0.0040345867 training Accuracy: 1.0000000000 validation acc: 0.601800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Training Loss: 0.0042656334 training Accuracy: 1.0000000000 validation acc: 0.597200\n",
      "Epoch 36, CIFAR-10 Batch 1:  Training Loss: 0.0056052054 training Accuracy: 1.0000000000 validation acc: 0.597000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Training Loss: 0.0050270334 training Accuracy: 1.0000000000 validation acc: 0.600800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Training Loss: 0.0033827142 training Accuracy: 1.0000000000 validation acc: 0.600200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Training Loss: 0.0040053562 training Accuracy: 1.0000000000 validation acc: 0.598200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Training Loss: 0.0043683862 training Accuracy: 1.0000000000 validation acc: 0.595600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Training Loss: 1.9756283760 training Accuracy: 0.3000000119 validation acc: 0.355000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Training Loss: 1.5828813314 training Accuracy: 0.5500000119 validation acc: 0.434400\n",
      "Epoch  1, CIFAR-10 Batch 3:  Training Loss: 1.3288760185 training Accuracy: 0.5250000358 validation acc: 0.472200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Training Loss: 1.3638236523 training Accuracy: 0.5250000358 validation acc: 0.488200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Training Loss: 1.4328789711 training Accuracy: 0.5749999881 validation acc: 0.519000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Training Loss: 1.4962068796 training Accuracy: 0.4500000179 validation acc: 0.514800\n",
      "Epoch  2, CIFAR-10 Batch 2:  Training Loss: 1.1266494989 training Accuracy: 0.6250000000 validation acc: 0.545200\n",
      "Epoch  2, CIFAR-10 Batch 3:  Training Loss: 0.9467594028 training Accuracy: 0.6750000119 validation acc: 0.544000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Training Loss: 1.0693168640 training Accuracy: 0.6250000000 validation acc: 0.555600\n",
      "Epoch  2, CIFAR-10 Batch 5:  Training Loss: 1.1006731987 training Accuracy: 0.6750000119 validation acc: 0.585800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Training Loss: 1.2813327312 training Accuracy: 0.6499999762 validation acc: 0.570000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Training Loss: 0.9772666693 training Accuracy: 0.6749999523 validation acc: 0.590600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Training Loss: 0.7247682810 training Accuracy: 0.7500000000 validation acc: 0.602200\n",
      "Epoch  3, CIFAR-10 Batch 4:  Training Loss: 0.8999208212 training Accuracy: 0.6999999881 validation acc: 0.610000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Training Loss: 0.9165868759 training Accuracy: 0.6749999523 validation acc: 0.622000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Training Loss: 1.0518293381 training Accuracy: 0.7000000477 validation acc: 0.614600\n",
      "Epoch  4, CIFAR-10 Batch 2:  Training Loss: 0.7772909403 training Accuracy: 0.7750000358 validation acc: 0.622200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Training Loss: 0.5850284100 training Accuracy: 0.8500000834 validation acc: 0.629600\n",
      "Epoch  4, CIFAR-10 Batch 4:  Training Loss: 0.7208528519 training Accuracy: 0.7500000000 validation acc: 0.629800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Training Loss: 0.7314599156 training Accuracy: 0.7500000000 validation acc: 0.636600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Training Loss: 0.8344755173 training Accuracy: 0.8000000715 validation acc: 0.632600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Training Loss: 0.6259236932 training Accuracy: 0.8000000119 validation acc: 0.643200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Training Loss: 0.4887785614 training Accuracy: 0.8500000834 validation acc: 0.652000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Training Loss: 0.6391683221 training Accuracy: 0.7999999523 validation acc: 0.649800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Training Loss: 0.6052591801 training Accuracy: 0.7999999523 validation acc: 0.656200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Training Loss: 0.7015271187 training Accuracy: 0.8250000477 validation acc: 0.662600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Training Loss: 0.4886890054 training Accuracy: 0.8500000834 validation acc: 0.668200\n",
      "Epoch  6, CIFAR-10 Batch 3:  Training Loss: 0.3755431473 training Accuracy: 0.9250000119 validation acc: 0.664200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Training Loss: 0.5128166676 training Accuracy: 0.8750000596 validation acc: 0.656200\n",
      "Epoch  6, CIFAR-10 Batch 5:  Training Loss: 0.4278533459 training Accuracy: 0.8999999762 validation acc: 0.677400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Training Loss: 0.6066311598 training Accuracy: 0.8250000477 validation acc: 0.670000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Training Loss: 0.3463903964 training Accuracy: 0.9250000119 validation acc: 0.674400\n",
      "Epoch  7, CIFAR-10 Batch 3:  Training Loss: 0.3037429154 training Accuracy: 0.9499999881 validation acc: 0.680600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Training Loss: 0.3821272850 training Accuracy: 0.9499999881 validation acc: 0.676000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Training Loss: 0.3459742665 training Accuracy: 0.9499999881 validation acc: 0.675600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Training Loss: 0.4386232495 training Accuracy: 0.8500000238 validation acc: 0.688600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Training Loss: 0.2723658383 training Accuracy: 0.9499999881 validation acc: 0.682000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Training Loss: 0.2525814772 training Accuracy: 1.0000000000 validation acc: 0.693400\n",
      "Epoch  8, CIFAR-10 Batch 4:  Training Loss: 0.2943553030 training Accuracy: 0.9250000119 validation acc: 0.683600\n",
      "Epoch  8, CIFAR-10 Batch 5:  Training Loss: 0.2610205412 training Accuracy: 0.9499999881 validation acc: 0.678400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Training Loss: 0.3736640215 training Accuracy: 0.8750000000 validation acc: 0.691000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Training Loss: 0.1803639829 training Accuracy: 1.0000000000 validation acc: 0.690800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Training Loss: 0.2013290226 training Accuracy: 1.0000000000 validation acc: 0.699000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Training Loss: 0.2225332409 training Accuracy: 0.9499999881 validation acc: 0.701800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Training Loss: 0.1853953898 training Accuracy: 0.9749999642 validation acc: 0.686200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Training Loss: 0.2628613114 training Accuracy: 0.9250000119 validation acc: 0.704000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Training Loss: 0.1257090867 training Accuracy: 1.0000000000 validation acc: 0.704400\n",
      "Epoch 10, CIFAR-10 Batch 3:  Training Loss: 0.1528119445 training Accuracy: 1.0000000000 validation acc: 0.694200\n",
      "Epoch 10, CIFAR-10 Batch 4:  Training Loss: 0.1603450775 training Accuracy: 0.9749999642 validation acc: 0.711600\n",
      "Epoch 10, CIFAR-10 Batch 5:  Training Loss: 0.1618047655 training Accuracy: 0.9749999642 validation acc: 0.678400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Training Loss: 0.1336929202 training Accuracy: 1.0000000000 validation acc: 0.707000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Training Loss: 0.0747189149 training Accuracy: 1.0000000000 validation acc: 0.709600\n",
      "Epoch 11, CIFAR-10 Batch 3:  Training Loss: 0.1016342044 training Accuracy: 1.0000000000 validation acc: 0.696600\n",
      "Epoch 11, CIFAR-10 Batch 4:  Training Loss: 0.1000929326 training Accuracy: 1.0000000000 validation acc: 0.705600\n",
      "Epoch 11, CIFAR-10 Batch 5:  Training Loss: 0.1217253059 training Accuracy: 1.0000000000 validation acc: 0.697400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Training Loss: 0.1154600978 training Accuracy: 1.0000000000 validation acc: 0.707800\n",
      "Epoch 12, CIFAR-10 Batch 2:  Training Loss: 0.0642057881 training Accuracy: 1.0000000000 validation acc: 0.711200\n",
      "Epoch 12, CIFAR-10 Batch 3:  Training Loss: 0.0908603370 training Accuracy: 1.0000000000 validation acc: 0.685800\n",
      "Epoch 12, CIFAR-10 Batch 4:  Training Loss: 0.0776136667 training Accuracy: 1.0000000000 validation acc: 0.699600\n",
      "Epoch 12, CIFAR-10 Batch 5:  Training Loss: 0.0529801957 training Accuracy: 1.0000000000 validation acc: 0.699600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Training Loss: 0.0861458257 training Accuracy: 1.0000000000 validation acc: 0.708600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Training Loss: 0.0401527807 training Accuracy: 1.0000000000 validation acc: 0.709800\n",
      "Epoch 13, CIFAR-10 Batch 3:  Training Loss: 0.0727243125 training Accuracy: 1.0000000000 validation acc: 0.699800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Training Loss: 0.0775139332 training Accuracy: 1.0000000000 validation acc: 0.697000\n",
      "Epoch 13, CIFAR-10 Batch 5:  Training Loss: 0.0330891684 training Accuracy: 1.0000000000 validation acc: 0.713600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Training Loss: 0.0527862534 training Accuracy: 1.0000000000 validation acc: 0.706200\n",
      "Epoch 14, CIFAR-10 Batch 2:  Training Loss: 0.0298525207 training Accuracy: 1.0000000000 validation acc: 0.711600\n",
      "Epoch 14, CIFAR-10 Batch 3:  Training Loss: 0.0464090183 training Accuracy: 1.0000000000 validation acc: 0.688600\n",
      "Epoch 14, CIFAR-10 Batch 4:  Training Loss: 0.0488797054 training Accuracy: 1.0000000000 validation acc: 0.702200\n",
      "Epoch 14, CIFAR-10 Batch 5:  Training Loss: 0.0196125340 training Accuracy: 1.0000000000 validation acc: 0.714600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Training Loss: 0.0486195199 training Accuracy: 1.0000000000 validation acc: 0.703400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Training Loss: 0.0279827192 training Accuracy: 1.0000000000 validation acc: 0.708200\n",
      "Epoch 15, CIFAR-10 Batch 3:  Training Loss: 0.0305450838 training Accuracy: 1.0000000000 validation acc: 0.705200\n",
      "Epoch 15, CIFAR-10 Batch 4:  Training Loss: 0.0312440265 training Accuracy: 1.0000000000 validation acc: 0.717400\n",
      "Epoch 15, CIFAR-10 Batch 5:  Training Loss: 0.0216985643 training Accuracy: 1.0000000000 validation acc: 0.718400\n",
      "Epoch 16, CIFAR-10 Batch 1:  Training Loss: 0.0236683134 training Accuracy: 1.0000000000 validation acc: 0.715200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Training Loss: 0.0367874429 training Accuracy: 1.0000000000 validation acc: 0.703200\n",
      "Epoch 16, CIFAR-10 Batch 3:  Training Loss: 0.0205053352 training Accuracy: 1.0000000000 validation acc: 0.696800\n",
      "Epoch 16, CIFAR-10 Batch 4:  Training Loss: 0.0264462177 training Accuracy: 1.0000000000 validation acc: 0.713600\n",
      "Epoch 16, CIFAR-10 Batch 5:  Training Loss: 0.0131091671 training Accuracy: 1.0000000000 validation acc: 0.717600\n",
      "Epoch 17, CIFAR-10 Batch 1:  Training Loss: 0.0182642080 training Accuracy: 1.0000000000 validation acc: 0.715800\n",
      "Epoch 17, CIFAR-10 Batch 2:  Training Loss: 0.0154080587 training Accuracy: 1.0000000000 validation acc: 0.709000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Training Loss: 0.0217746664 training Accuracy: 1.0000000000 validation acc: 0.697800\n",
      "Epoch 17, CIFAR-10 Batch 4:  Training Loss: 0.0116246697 training Accuracy: 1.0000000000 validation acc: 0.722000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Training Loss: 0.0164217409 training Accuracy: 1.0000000000 validation acc: 0.716000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Training Loss: 0.0161327925 training Accuracy: 1.0000000000 validation acc: 0.714600\n",
      "Epoch 18, CIFAR-10 Batch 2:  Training Loss: 0.0136672370 training Accuracy: 1.0000000000 validation acc: 0.706800\n",
      "Epoch 18, CIFAR-10 Batch 3:  Training Loss: 0.0113026071 training Accuracy: 1.0000000000 validation acc: 0.696600\n",
      "Epoch 18, CIFAR-10 Batch 4:  Training Loss: 0.0264765490 training Accuracy: 1.0000000000 validation acc: 0.709000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Training Loss: 0.0139126806 training Accuracy: 1.0000000000 validation acc: 0.702000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Training Loss: 0.0155145181 training Accuracy: 1.0000000000 validation acc: 0.701000\n",
      "Epoch 19, CIFAR-10 Batch 2:  Training Loss: 0.0232566670 training Accuracy: 1.0000000000 validation acc: 0.714800\n",
      "Epoch 19, CIFAR-10 Batch 3:  Training Loss: 0.0131594092 training Accuracy: 1.0000000000 validation acc: 0.709400\n",
      "Epoch 19, CIFAR-10 Batch 4:  Training Loss: 0.0092492010 training Accuracy: 1.0000000000 validation acc: 0.721600\n",
      "Epoch 19, CIFAR-10 Batch 5:  Training Loss: 0.0055431663 training Accuracy: 1.0000000000 validation acc: 0.719800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Training Loss: 0.0124473255 training Accuracy: 1.0000000000 validation acc: 0.714400\n",
      "Epoch 20, CIFAR-10 Batch 2:  Training Loss: 0.0046811681 training Accuracy: 1.0000000000 validation acc: 0.706000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Training Loss: 0.0243417080 training Accuracy: 1.0000000000 validation acc: 0.717600\n",
      "Epoch 20, CIFAR-10 Batch 4:  Training Loss: 0.0076186853 training Accuracy: 1.0000000000 validation acc: 0.723400\n",
      "Epoch 20, CIFAR-10 Batch 5:  Training Loss: 0.0044724913 training Accuracy: 1.0000000000 validation acc: 0.705600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Training Loss: 0.0073811342 training Accuracy: 1.0000000000 validation acc: 0.712400\n",
      "Epoch 21, CIFAR-10 Batch 2:  Training Loss: 0.0022798553 training Accuracy: 1.0000000000 validation acc: 0.704000\n",
      "Epoch 21, CIFAR-10 Batch 3:  Training Loss: 0.0178351905 training Accuracy: 1.0000000000 validation acc: 0.720400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Training Loss: 0.0089329453 training Accuracy: 1.0000000000 validation acc: 0.711200\n",
      "Epoch 21, CIFAR-10 Batch 5:  Training Loss: 0.0039005519 training Accuracy: 1.0000000000 validation acc: 0.719000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Training Loss: 0.0062850434 training Accuracy: 1.0000000000 validation acc: 0.707600\n",
      "Epoch 22, CIFAR-10 Batch 2:  Training Loss: 0.0033664159 training Accuracy: 1.0000000000 validation acc: 0.710600\n",
      "Epoch 22, CIFAR-10 Batch 3:  Training Loss: 0.0042251609 training Accuracy: 1.0000000000 validation acc: 0.712400\n",
      "Epoch 22, CIFAR-10 Batch 4:  Training Loss: 0.0055362293 training Accuracy: 1.0000000000 validation acc: 0.715200\n",
      "Epoch 22, CIFAR-10 Batch 5:  Training Loss: 0.0021399981 training Accuracy: 1.0000000000 validation acc: 0.724200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Training Loss: 0.0020149837 training Accuracy: 1.0000000000 validation acc: 0.711800\n",
      "Epoch 23, CIFAR-10 Batch 2:  Training Loss: 0.0020758454 training Accuracy: 1.0000000000 validation acc: 0.711600\n",
      "Epoch 23, CIFAR-10 Batch 3:  Training Loss: 0.0032711593 training Accuracy: 1.0000000000 validation acc: 0.712800\n",
      "Epoch 23, CIFAR-10 Batch 4:  Training Loss: 0.0060048448 training Accuracy: 1.0000000000 validation acc: 0.720200\n",
      "Epoch 23, CIFAR-10 Batch 5:  Training Loss: 0.0030853257 training Accuracy: 1.0000000000 validation acc: 0.720600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Training Loss: 0.0040810192 training Accuracy: 1.0000000000 validation acc: 0.711600\n",
      "Epoch 24, CIFAR-10 Batch 2:  Training Loss: 0.0020010641 training Accuracy: 1.0000000000 validation acc: 0.711000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Training Loss: 0.0027129124 training Accuracy: 1.0000000000 validation acc: 0.721800\n",
      "Epoch 24, CIFAR-10 Batch 4:  Training Loss: 0.0028498983 training Accuracy: 1.0000000000 validation acc: 0.715200\n",
      "Epoch 24, CIFAR-10 Batch 5:  Training Loss: 0.0083735520 training Accuracy: 1.0000000000 validation acc: 0.714800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Training Loss: 0.0013410313 training Accuracy: 1.0000000000 validation acc: 0.712600\n",
      "Epoch 25, CIFAR-10 Batch 2:  Training Loss: 0.0023598436 training Accuracy: 1.0000000000 validation acc: 0.708400\n",
      "Epoch 25, CIFAR-10 Batch 3:  Training Loss: 0.0067555890 training Accuracy: 1.0000000000 validation acc: 0.716800\n",
      "Epoch 25, CIFAR-10 Batch 4:  Training Loss: 0.0035588909 training Accuracy: 1.0000000000 validation acc: 0.717600\n",
      "Epoch 25, CIFAR-10 Batch 5:  Training Loss: 0.0036341667 training Accuracy: 1.0000000000 validation acc: 0.713400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Training Loss: 0.0009218095 training Accuracy: 1.0000000000 validation acc: 0.718400\n",
      "Epoch 26, CIFAR-10 Batch 2:  Training Loss: 0.0014506201 training Accuracy: 1.0000000000 validation acc: 0.714000\n",
      "Epoch 26, CIFAR-10 Batch 3:  Training Loss: 0.0035689292 training Accuracy: 1.0000000000 validation acc: 0.716800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Training Loss: 0.0046287831 training Accuracy: 1.0000000000 validation acc: 0.715400\n",
      "Epoch 26, CIFAR-10 Batch 5:  Training Loss: 0.0040957946 training Accuracy: 1.0000000000 validation acc: 0.716200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Training Loss: 0.0015992321 training Accuracy: 1.0000000000 validation acc: 0.724200\n",
      "Epoch 27, CIFAR-10 Batch 2:  Training Loss: 0.0019698110 training Accuracy: 1.0000000000 validation acc: 0.707400\n",
      "Epoch 27, CIFAR-10 Batch 3:  Training Loss: 0.0021636314 training Accuracy: 1.0000000000 validation acc: 0.717800\n",
      "Epoch 27, CIFAR-10 Batch 4:  Training Loss: 0.0016427902 training Accuracy: 1.0000000000 validation acc: 0.723400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Training Loss: 0.0016955552 training Accuracy: 1.0000000000 validation acc: 0.720200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Training Loss: 0.0019191013 training Accuracy: 1.0000000000 validation acc: 0.718400\n",
      "Epoch 28, CIFAR-10 Batch 2:  Training Loss: 0.0025358524 training Accuracy: 1.0000000000 validation acc: 0.702400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Training Loss: 0.0011587006 training Accuracy: 1.0000000000 validation acc: 0.723400\n",
      "Epoch 28, CIFAR-10 Batch 4:  Training Loss: 0.0016171229 training Accuracy: 1.0000000000 validation acc: 0.720400\n",
      "Epoch 28, CIFAR-10 Batch 5:  Training Loss: 0.0013605119 training Accuracy: 1.0000000000 validation acc: 0.730600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Training Loss: 0.0037036920 training Accuracy: 1.0000000000 validation acc: 0.716400\n",
      "Epoch 29, CIFAR-10 Batch 2:  Training Loss: 0.0010708667 training Accuracy: 1.0000000000 validation acc: 0.711800\n",
      "Epoch 29, CIFAR-10 Batch 3:  Training Loss: 0.0021082307 training Accuracy: 1.0000000000 validation acc: 0.727800\n",
      "Epoch 29, CIFAR-10 Batch 4:  Training Loss: 0.0049444186 training Accuracy: 1.0000000000 validation acc: 0.718800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Training Loss: 0.0014575766 training Accuracy: 1.0000000000 validation acc: 0.724000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Training Loss: 0.0016434180 training Accuracy: 1.0000000000 validation acc: 0.714200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Training Loss: 0.0007176014 training Accuracy: 1.0000000000 validation acc: 0.707200\n",
      "Epoch 30, CIFAR-10 Batch 3:  Training Loss: 0.0011989872 training Accuracy: 1.0000000000 validation acc: 0.727800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Training Loss: 0.0023550924 training Accuracy: 1.0000000000 validation acc: 0.720600\n",
      "Epoch 30, CIFAR-10 Batch 5:  Training Loss: 0.0010107083 training Accuracy: 1.0000000000 validation acc: 0.726800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Training Loss: 0.0020888718 training Accuracy: 1.0000000000 validation acc: 0.716200\n",
      "Epoch 31, CIFAR-10 Batch 2:  Training Loss: 0.0018455270 training Accuracy: 1.0000000000 validation acc: 0.717600\n",
      "Epoch 31, CIFAR-10 Batch 3:  Training Loss: 0.0023491632 training Accuracy: 1.0000000000 validation acc: 0.725200\n",
      "Epoch 31, CIFAR-10 Batch 4:  Training Loss: 0.0023627710 training Accuracy: 1.0000000000 validation acc: 0.714000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Training Loss: 0.0004875408 training Accuracy: 1.0000000000 validation acc: 0.718200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Training Loss: 0.0009692947 training Accuracy: 1.0000000000 validation acc: 0.712800\n",
      "Epoch 32, CIFAR-10 Batch 2:  Training Loss: 0.0007055808 training Accuracy: 1.0000000000 validation acc: 0.720600\n",
      "Epoch 32, CIFAR-10 Batch 3:  Training Loss: 0.0012354197 training Accuracy: 1.0000000000 validation acc: 0.723200\n",
      "Epoch 32, CIFAR-10 Batch 4:  Training Loss: 0.0009026901 training Accuracy: 1.0000000000 validation acc: 0.720600\n",
      "Epoch 32, CIFAR-10 Batch 5:  Training Loss: 0.0006389864 training Accuracy: 1.0000000000 validation acc: 0.714400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Training Loss: 0.0009714114 training Accuracy: 1.0000000000 validation acc: 0.719200\n",
      "Epoch 33, CIFAR-10 Batch 2:  Training Loss: 0.0009030959 training Accuracy: 1.0000000000 validation acc: 0.722400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Training Loss: 0.0029209591 training Accuracy: 1.0000000000 validation acc: 0.710200\n",
      "Epoch 33, CIFAR-10 Batch 4:  Training Loss: 0.0015657616 training Accuracy: 1.0000000000 validation acc: 0.726200\n",
      "Epoch 33, CIFAR-10 Batch 5:  Training Loss: 0.0004634443 training Accuracy: 1.0000000000 validation acc: 0.725400\n",
      "Epoch 34, CIFAR-10 Batch 1:  Training Loss: 0.0006880359 training Accuracy: 1.0000000000 validation acc: 0.709200\n",
      "Epoch 34, CIFAR-10 Batch 2:  Training Loss: 0.0004436112 training Accuracy: 1.0000000000 validation acc: 0.722600\n",
      "Epoch 34, CIFAR-10 Batch 3:  Training Loss: 0.0027198503 training Accuracy: 1.0000000000 validation acc: 0.720600\n",
      "Epoch 34, CIFAR-10 Batch 4:  Training Loss: 0.0007183225 training Accuracy: 1.0000000000 validation acc: 0.713400\n",
      "Epoch 34, CIFAR-10 Batch 5:  Training Loss: 0.0004969154 training Accuracy: 1.0000000000 validation acc: 0.723600\n",
      "Epoch 35, CIFAR-10 Batch 1:  Training Loss: 0.0012934274 training Accuracy: 1.0000000000 validation acc: 0.714400\n",
      "Epoch 35, CIFAR-10 Batch 2:  Training Loss: 0.0008762190 training Accuracy: 1.0000000000 validation acc: 0.722200\n",
      "Epoch 35, CIFAR-10 Batch 3:  Training Loss: 0.0041070404 training Accuracy: 1.0000000000 validation acc: 0.717400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Training Loss: 0.0004501150 training Accuracy: 1.0000000000 validation acc: 0.719600\n",
      "Epoch 35, CIFAR-10 Batch 5:  Training Loss: 0.0018061582 training Accuracy: 1.0000000000 validation acc: 0.720800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Training Loss: 0.0006209843 training Accuracy: 1.0000000000 validation acc: 0.717600\n",
      "Epoch 36, CIFAR-10 Batch 2:  Training Loss: 0.0014773470 training Accuracy: 1.0000000000 validation acc: 0.721800\n",
      "Epoch 36, CIFAR-10 Batch 3:  Training Loss: 0.0005567333 training Accuracy: 1.0000000000 validation acc: 0.728400\n",
      "Epoch 36, CIFAR-10 Batch 4:  Training Loss: 0.0002199241 training Accuracy: 1.0000000000 validation acc: 0.720800\n",
      "Epoch 36, CIFAR-10 Batch 5:  Training Loss: 0.0002116004 training Accuracy: 1.0000000000 validation acc: 0.720800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Training Loss: 0.0012115717 training Accuracy: 1.0000000000 validation acc: 0.714400\n",
      "Epoch 37, CIFAR-10 Batch 2:  Training Loss: 0.0010713035 training Accuracy: 1.0000000000 validation acc: 0.719200\n",
      "Epoch 37, CIFAR-10 Batch 3:  Training Loss: 0.0003745826 training Accuracy: 1.0000000000 validation acc: 0.720600\n",
      "Epoch 37, CIFAR-10 Batch 4:  Training Loss: 0.0003530329 training Accuracy: 1.0000000000 validation acc: 0.722400\n",
      "Epoch 37, CIFAR-10 Batch 5:  Training Loss: 0.0007292514 training Accuracy: 1.0000000000 validation acc: 0.725600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Training Loss: 0.0007500855 training Accuracy: 1.0000000000 validation acc: 0.715000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Training Loss: 0.0007987009 training Accuracy: 1.0000000000 validation acc: 0.719600\n",
      "Epoch 38, CIFAR-10 Batch 3:  Training Loss: 0.0003154255 training Accuracy: 1.0000000000 validation acc: 0.724200\n",
      "Epoch 38, CIFAR-10 Batch 4:  Training Loss: 0.0007085602 training Accuracy: 1.0000000000 validation acc: 0.722000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Training Loss: 0.0002457898 training Accuracy: 1.0000000000 validation acc: 0.717800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Training Loss: 0.0004566222 training Accuracy: 1.0000000000 validation acc: 0.722000\n",
      "Epoch 39, CIFAR-10 Batch 2:  Training Loss: 0.0029933061 training Accuracy: 1.0000000000 validation acc: 0.721400\n",
      "Epoch 39, CIFAR-10 Batch 3:  Training Loss: 0.0011456627 training Accuracy: 1.0000000000 validation acc: 0.728000\n",
      "Epoch 39, CIFAR-10 Batch 4:  Training Loss: 0.0002909146 training Accuracy: 1.0000000000 validation acc: 0.729000\n",
      "Epoch 39, CIFAR-10 Batch 5:  Training Loss: 0.0004569088 training Accuracy: 1.0000000000 validation acc: 0.724800\n",
      "Epoch 40, CIFAR-10 Batch 1:  Training Loss: 0.0004537118 training Accuracy: 1.0000000000 validation acc: 0.719800\n",
      "Epoch 40, CIFAR-10 Batch 2:  Training Loss: 0.0005934104 training Accuracy: 1.0000000000 validation acc: 0.710600\n",
      "Epoch 40, CIFAR-10 Batch 3:  Training Loss: 0.0009129298 training Accuracy: 1.0000000000 validation acc: 0.725800\n",
      "Epoch 40, CIFAR-10 Batch 4:  Training Loss: 0.0006447557 training Accuracy: 1.0000000000 validation acc: 0.716200\n",
      "Epoch 40, CIFAR-10 Batch 5:  Training Loss: 0.0001141171 training Accuracy: 1.0000000000 validation acc: 0.720200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "        # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7141020569620253\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZmZJQ6OzczMzMwSB8dmZmZmZsn/Ak+ddO6Zkze8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa5b49c8828>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN. Pure guessing would get you 10% accuracy. However, you might notice people are getting scores well above 70%. That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
